# Binary-Classification-using-Tensorflow

## Terminology

* Batch Size</br>
  It is a hyperparameter which defines the number of samples the algorithm would work through before the internal parameters are updated.
* Epoch</br>
  Number of epochs reflects the number of iterations the learning algorithm will undergo while working through the entire dataset.
* Perceptrons</br>
  A machine learning construct usually used for classification tasks.
* Stochastic Gradient Descent</br>
  When the batch_size = 1.
* Batch Gradient Descent</br>
  When epoch = 1.

## Important considerations

* What should be the batch_size?
* Gradient descent vs stochastic gradient descent vs mini-batch gradient descent

## Common questions


## Checklist

- [x] Classification (normally distributed clusters)
- [ ] Plot learning curve of model vaildation error against training time
- [ ] Tune batch size and learning rate 
